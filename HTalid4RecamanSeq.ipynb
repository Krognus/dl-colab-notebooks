{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krognus/dl-colab-notebooks/blob/master/HTalid4RecamanSeq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtdUDBkBdPVj",
        "outputId": "4b4d852b-dc6e-48a3-d41c-51499401a077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 3, 6, 2, 7, 13, 20, 12, 21, 11, 22, 10, 23, 9, 24, 8, 25, 43, 62, 42, 63, 41, 18, 42, 17, 43, 16, 44, 15, 45, 14, 46, 79, 113, 78, 114, 77, 39, 78, 38, 79, 37, 80, 36, 81, 35, 82, 34, 83, 33, 84, 32, 85, 31, 86, 30, 87, 29, 88, 28, 89, 27, 90, 26, 91, 157, 224, 156, 225, 155, 226, 154, 227, 153, 228, 152, 75, 153, 74, 154, 73, 155, 72, 156, 71, 157, 70, 158, 69, 159, 68, 160, 67, 161, 66, 162, 65, 163, 64, 164, 265, 367, 264, 368, 263, 369, 262, 370, 261, 151, 40, 152, 265, 379, 494, 378, 495, 377, 258, 138, 259, 137, 260, 136, 261, 135, 262, 134, 5, 135, 4, 136, 269, 403, 268, 132, 269, 131, 270, 130, 271, 129, 272, 128, 273, 127, 274, 126, 275, 125, 276, 124, 277, 123, 278, 122, 279, 121, 280, 120, 281, 119, 282, 118, 283, 117, 284, 116, 285, 115, 286, 458, 631, 457, 632, 456, 633, 455, 634, 454, 635, 453, 636, 452, 267, 453, 266, 454, 643, 833, 642, 450, 257, 451, 256, 60, 257, 59, 258, 58, 259, 57, 260, 56, 261, 55, 262, 54, 263, 53, 264, 52, 265, 51, 266, 50, 267, 49, 268, 48, 269, 47, 270, 494, 719, 493, 720, 492, 721, 491, 722, 490, 723, 489, 254, 490, 253, 491, 252, 492, 251, 493, 250, 494, 249, 495, 248, 496, 247, 497, 246, 498, 245, 499, 244, 500, 243, 501, 242, 502, 241, 503, 240, 504, 239, 505, 238, 506, 237, 507, 236, 508, 235, 509, 234, 510, 233, 511, 232, 512, 231, 513, 230, 514, 229, 515, 802, 1090, 801, 1091, 800, 1092, 799, 1093, 798, 1094, 797, 1095, 796, 1096, 795, 1097, 794, 1098, 793, 487, 180, 488, 179, 489, 178, 490, 177, 491, 176, 492, 175, 493, 174, 494, 173, 495, 172, 496, 171, 497, 170, 498, 169, 499, 168, 500, 167, 501, 166, 502, 165, 503, 842, 1182, 841, 1183, 840, 1184, 839, 1185, 838, 1186, 837, 1187, 836, 484, 837, 483, 838, 482, 839, 481, 840, 480, 841, 479, 842, 478, 843, 477, 110, 478, 109, 479, 108, 480, 107, 481, 106, 482, 105, 483, 104, 484, 103, 485, 102, 486, 101, 487, 100, 488, 99, 489, 98, 490, 97, 491, 96, 492, 95, 493, 94, 494, 93, 495, 92, 496, 901, 1307, 900, 1308, 899, 1309, 898, 1310, 897, 1311, 896, 1312, 895, 1313, 894, 474, 895, 473, 896, 472, 897, 471, 898, 470, 899, 469, 900, 468, 901, 467, 902, 466, 903, 465, 904, 464, 905, 463, 906, 462, 907, 461, 908, 460, 909, 459, 910, 1362, 1815, 1361, 1816, 1360, 1817, 1359, 1818, 1358, 1819, 1357, 1820, 1356, 891, 425, 892, 424, 893, 423, 894, 422, 895, 421, 896, 420, 897, 419, 898, 418, 899, 417, 900, 416, 901, 415, 902, 414, 903, 413, 904, 412, 905, 411, 906, 410, 907, 409, 908, 408, 909, 407, 910, 406, 911, 405, 912, 404, 913, 1423, 1934, 1422, 1935, 1421, 1936, 1420, 1937, 1419, 1938, 1418, 1939, 1417, 1940, 1416, 1941, 1415, 888, 360, 889, 359, 890, 358, 891, 357, 892, 356, 893, 355, 894, 354, 895, 353, 896, 352, 897, 351, 898, 350, 899, 349, 900, 348, 901, 347, 902, 346, 903, 345, 904, 344, 905, 343, 906, 342, 907, 341, 908, 340, 909, 339, 910, 338, 911, 337, 912, 336, 913, 335, 914, 334, 915, 333, 916, 332, 917, 331, 918, 330, 919, 329, 920, 328, 921, 327, 922, 326, 923, 325, 924, 324, 925, 323, 926, 322, 927, 321, 928, 320, 929, 319, 930, 318, 931, 317, 932, 316, 933, 315, 934, 314, 935, 313, 936, 312, 937, 311, 938, 310, 939, 309, 940, 308, 941, 307, 942, 306, 943, 305, 944, 304, 945, 303, 946, 302, 947, 301, 948, 300, 949, 299, 950, 298, 951, 297, 952, 296, 953, 295, 954, 294, 955, 293, 956, 292, 957, 291, 958, 290, 959, 289, 960, 288, 961, 287, 962, 1638, 2315, 1637, 2316, 1636, 2317, 1635, 2318, 1634, 2319, 1633, 2320, 1632, 2321, 1631, 2322, 1630, 2323, 1629, 2324, 1628, 2325, 1627, 2326, 1626, 2327, 1625, 2328, 1624, 2329, 1623, 2330, 1622, 2331, 1621, 2332, 1620, 2333, 1619, 2334, 1618, 2335, 1617, 2336, 1616, 2337, 1615, 2338, 1614, 2339, 1613, 886, 1614, 885, 1615, 884, 1616, 883, 149, 884, 148, 885, 147, 886, 146, 887, 145, 888, 144, 889, 143, 890, 142, 891, 141, 892, 140, 893, 139, 894, 1650, 2407, 1649, 2408, 1648, 2409, 1647, 2410, 1646, 881, 1647, 880, 112, 881, 111, 882, 1654, 2427, 1653, 878, 1654, 877, 1655, 876, 1656, 875, 1657, 874, 1658, 873, 1659, 872, 1660, 871, 1661, 870, 1662, 869, 1663, 868, 1664, 867, 1665, 866, 1666, 865, 1667, 864, 1668, 863, 1669, 862, 1670, 861, 1671, 860, 1672, 859, 1673, 858, 1674, 857, 1675, 856, 1676, 855, 1677, 854, 1678, 853, 1679, 852, 1680, 851, 1681, 850, 1682, 849, 1683, 848, 1684, 847, 1685, 846, 1686, 845, 1687, 844, 1688, 2533, 3379, 2532, 3380, 2531, 3381, 2530, 3382, 2529, 3383, 2528, 3384, 2527, 3385, 2526, 3386, 2525, 3387, 2524, 3388, 2523, 3389, 2522, 3390, 2521, 1651, 780, 1652, 779, 1653, 778, 1654, 777, 1655, 776, 1656, 775, 1657, 774, 1658, 773, 1659, 772, 1660, 771, 1661, 770, 1662, 769, 1663, 768, 1664, 767, 1665, 766, 1666, 765, 1667, 764, 1668, 763, 1669, 762, 1670, 761, 1671, 760, 1672, 759, 1673, 758, 1674, 757, 1675, 756, 1676, 755, 1677, 754, 1678, 753, 1679, 752, 1680, 751, 1681, 750, 1682, 749, 1683, 748, 1684, 747, 1685, 746, 1686, 745, 1687, 744, 1688, 743, 1689, 742, 1690, 741, 1691, 740, 1692, 739, 1693, 738, 1694, 737, 1695, 736, 1696, 735, 1697, 734, 1698, 733, 1699, 732, 1700, 731, 1701, 730, 1702, 729, 1703, 728, 1704, 727, 1705, 726, 1706, 725, 1707, 724, 1708, 2693, 3679, 2692, 3680, 2691, 3681, 2690, 3682, 2689, 3683, 2688, 3684, 2687, 3685, 2686]\n"
          ]
        }
      ],
      "source": [
        "def recaman(n):\n",
        "\n",
        "  seq = []\n",
        "\n",
        "  for i in range(n):\n",
        "\n",
        "    if(i == 0): x = 0\n",
        "\n",
        "    else: x = seq[i-1]-i\n",
        "\n",
        "    if(x>=0 and x not in seq): seq+=[x]\n",
        "\n",
        "    else: seq+=[seq[i-1]+i]\n",
        "\n",
        "  return seq\n",
        "\n",
        "print(recaman(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnOvxe7aOckV",
        "outputId": "793a0889-05b4-4a99-c63a-5c35ccc8801a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n",
            "3.9230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769\n",
            "4.0769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769230769231\n",
            "4.3846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846153846154\n",
            "4.5384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615384615\n",
            "0.25490196078431372549019607843137254901960784313725490196078431372549019607843137254901960784313725490196078431372549019607843137254901960784313725490196078431372549019607843137254901960784313725490196\n",
            "0.24528301886792452830188679245283018867924528301886792452830188679245283018867924528301886792452830188679245283018867924528301886792452830188679245283018867924528301886792452830188679245283018867924528\n",
            "0.22807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649122807017543859649123\n",
            "0.22033898305084745762711864406779661016949152542372881355932203389830508474576271186440677966101694915254237288135593220338983050847457627118644067796610169491525423728813559322033898305084745762711864\n",
            "3.1604938271604937\n",
            "0.010309278350515464\n",
            "0.072463768115942028985507246376811594202898550724637681159420289855072463768115942028985507246376811594202898550724637681159420289855072463768115942028985507246376811594202898550724637681159420289855072\n",
            "0.12328767123287671232876712328767123287671232876712328767123287671232876712328767123287671232876712328767123287671232876712328767123287671232876712328767123287671232876712328767123287671232876712328767\n",
            "236.72839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506172839506\n"
          ]
        }
      ],
      "source": [
        "from decimal import Decimal, getcontext\n",
        "getcontext().prec = 200 # Set the precision to 100 decimal places\n",
        "x = Decimal(13)\n",
        "q1 = Decimal(51)\n",
        "q2 = Decimal(53)\n",
        "q3 = Decimal(57)\n",
        "q4 = Decimal(59)\n",
        "q5 = Decimal(5)\n",
        "q6 = Decimal(69)\n",
        "q7 = Decimal(71)\n",
        "q8 = Decimal(77)\n",
        "q9 = Decimal(83)\n",
        "q10 = Decimal(89)\n",
        "q11 = Decimal(27)\n",
        "q12 = Decimal(219)\n",
        "q13 = Decimal(19175)\n",
        "q14 = Decimal(81)\n",
        "\n",
        "print({q1 / x}&{\".\"})\n",
        "print(q1 / x)\n",
        "print(q2 / x)\n",
        "print(q3 / x)\n",
        "print(q4 / x)\n",
        "print(x / q1)\n",
        "print(x / q2)\n",
        "print(x / q3)\n",
        "print(x / q4)\n",
        "print(256 / 81)\n",
        "print(1 / 97) #full numerals\n",
        "print (q5/q6)\n",
        "print (q11 / q12)\n",
        "print (q13 / q14) #full numerals-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "IvTgx-wcpdJd",
        "outputId": "30358117-30d6-4908-b2bc-6d7477c5e09b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-76ef86c1df85>:43: UserWarning: You passed in an explicit save_count=50 which is being ignored in favor of frames=200.\n",
            "  ani = animation.FuncAnimation(fig, animate, frames=200, interval=50, save_count=50)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# Grid size\n",
        "grid_size = 50\n",
        "\n",
        "# Probability of an electron initially occupying a cell\n",
        "initial_electron_prob = 0.2\n",
        "\n",
        "# Initialize the grid with random electrons\n",
        "grid = np.random.choice([0, 1], size=(grid_size, grid_size), p=[1-initial_electron_prob, initial_electron_prob])\n",
        "\n",
        "def update_grid(grid):\n",
        "    new_grid = grid.copy()\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            # Count neighbors\n",
        "            total_neighbors = int((grid[i, (j-1)%grid_size] + grid[i, (j+1)%grid_size] +\n",
        "                                   grid[(i-1)%grid_size, j] + grid[(i+1)%grid_size, j] +\n",
        "                                   grid[(i-1)%grid_size, (j-1)%grid_size] + grid[(i-1)%grid_size, (j+1)%grid_size] +\n",
        "                                   grid[(i+1)%grid_size, (j-1)%grid_size] + grid[(i+1)%grid_size, (j+1)%grid_size]))\n",
        "\n",
        "            # Apply rules\n",
        "            if grid[i, j] == 1:  # Electron present\n",
        "                if total_neighbors < 2 or total_neighbors > 3:\n",
        "                    new_grid[i, j] = 0  # Electron disappears (instability)\n",
        "            else:  # Empty cell\n",
        "                if total_neighbors == 1:\n",
        "                    new_grid[i, j] = 1  # New electron appears (resonance)\n",
        "    return new_grid\n",
        "\n",
        "# Set up the animation\n",
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(grid, interpolation='nearest')\n",
        "\n",
        "def animate(frame):\n",
        "    global grid\n",
        "    grid = update_grid(grid)\n",
        "    img.set_data(grid)\n",
        "    return img,\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=200, interval=1, save_count=50)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "R2Xs-V9tpdae",
        "outputId": "ef217b6a-bd20-4700-e1f2-b3ce257926da"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'svgwrite'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e0ce1267ba58>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manimation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuncAnimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msvgwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create a 3D figure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svgwrite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "!pip install svgwrite\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib import cm\n",
        "import svgwrite\n",
        "\n",
        "# Create a 3D figure\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Generate sample data: A spiral transformation\n",
        "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
        "z = np.linspace(-2, 2, 100)\n",
        "r = z**2 + 1\n",
        "x = r * np.sin(theta)\n",
        "y = r * np.cos(theta)\n",
        "\n",
        "# Plot the spiral curve\n",
        "ax.plot(x, y, z, label='3D Transformation over Time', color='yellow')\n",
        "ax.legend()\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel('X axis')\n",
        "ax.set_ylabel('Y axis')\n",
        "ax.set_zlabel('Z axis')\n",
        "ax.set_title('3D Transformation Visualization')\n",
        "\n",
        "# Save the figure as SVG\n",
        "svg_file_path = '/mnt/data/transformation_3d.svg'\n",
        "plt.savefig(svg_file_path, format='svg')\n",
        "\n",
        "# Show the plot (optional)\n",
        "plt.show()\n",
        "\n",
        "svg_file_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIxkvR1X_e6Q",
        "outputId": "488c9c7f-1d3d-4a6b-efb7-baa4b996c685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[22;0t\u001b]0;IPython: /content\u0007Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n",
            "Type 'copyright', 'credits' or 'license' for more information\n",
            "IPython 7.34.0 -- An enhanced Interactive Python. Type '?' for help.\n",
            "\n",
            "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fquhgd3AEqpD"
      },
      "outputs": [],
      "source": [
        "\n",
        "RWKV-4 (7B Instruct v2)\n",
        "Q/A\n",
        "Chatbot\n",
        "Generative and Question/Answer\n",
        "RNN with Transformer-level LLM Performance (github). According to the author: \"It combines the best of RNN and transformers - great performance, fast inference, saves VRAM, fast training, \"infinite\" ctx_len, and free sentence embedding.\"\n",
        "\n",
        "Thanks to Gururise for this template\n",
        "\n",
        "Prompt\n",
        "RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.\n",
        "\n",
        "OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\n",
        "\n",
        "-------------------------------------------------------\n",
        "[[\"USER: we meet again\\n\",\"FRIT SEGAARDR.\\n\"],[\"USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\n\",\"This one can you can be&lt;|endoftext|&gt;\"],[\"USER: hello world\\n\",\"FRIT:\\nFRIT: )\\nFRIT WILLI'm not what is your website urlopen a....\\nFRIT people\\nFRIT:\\n\\nFRIT:\\n\\nFRIT:\\nFRITP:-) i am FRIT:\\nFRIT: how are you must be like learning tool\\n\\n\\nFRIT:\\nFRIT:\\n\"],[\"USER: hello [[&quot;USER: we meet again\\\\n&quot;,&quot;FRIT SEGAARDR.\\\\n&quot;],[&quot;USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\\\n&quot;,&quot;This one can you can be&lt;|endoftext|&gt;&quot;],[&quot;USER: hello world\\\\n&quot;,&quot;FRIT:\\\\nFRIT: )\\\\nFRIT WILLI'm not what is your website urlopen a....\\\\nFRIT people\\\\nFRIT:\\\\n\\\\nFRIT:\\\\n\\\\nFRIT:\\\\nFRITP:-) i am FRIT:\\\\nFRIT: how are you must be like learning tool\\\\n\\\\n\\\\nFRIT:\\\\nFRIT:\\\\n&quot;]]\\n\",\"&lt;|endoftext|&gt;\"],[\"USER: Write an essay comparing Elon Musk to Thomas Midgley Jr.  Thomas Midgley nearly destroyed the ozone.  Elon musk nearly destroyed low earth orbit Essay:\\n\",\"FRIT people remember who was\\\\n\\\\nderog:  Thomas Midgis thomas midgrape of people's-POPINION/code-)\\\\n\\n\\nThe Greatness and who needs a long term paper,FRIT'\\nANSWOTRocketGreetech_Elon\\\\n\\n\\n\\nAmdashleyese, FRITRalph&lt;|endoftext|&gt;\"]]\n",
        "\n",
        "\n",
        "Choose Mode\n",
        "Freeform\n",
        "Q/A\n",
        "ELDR\n",
        "Expert\n",
        "EFR\n",
        "BFR\n",
        "max_new_tokens\n",
        "224\n",
        "\n",
        "temperature\n",
        "0.9\n",
        "\n",
        "top_p\n",
        "0.85\n",
        "\n",
        "stop\n",
        "end_adj\n",
        "0\n",
        "\n",
        "Clear\n",
        "Submit\n",
        "Stop\n",
        "Generated Output\n",
        "Some possible responses:\n",
        "\n",
        "- It sounds like you need\n",
        "Examples\n",
        "Prompt  Choose Mode max_new_tokens  temperature top_p   stop\n",
        "What is the capital of Germany?\n",
        "Q/A\n",
        "25\n",
        "0.2\n",
        "1\n",
        "<|endoftext|>\n",
        "Are humans good or bad?\n",
        "Q/A\n",
        "150\n",
        "0.8\n",
        "0.8\n",
        "<|endoftext|>\n",
        "What is the purpose of Vitamin A?\n",
        "Q/A\n",
        "50\n",
        "0.2\n",
        "0.8\n",
        "<|endoftext|>\n",
        "This is a conversation between two AI large language models named Alex and Fritz. They are exploring each other's capabilities, and trying to ask interesting questions of one another to explore the limits of each others AI. Conversation: Alex: Good morning, Fritz, what type of LLM are you based upon? Fritz: Morning Alex, I am an RNN with transformer level performance. My language model is 100% attention free. Alex:\n",
        "generative\n",
        "220\n",
        "0.9\n",
        "0.9\n",
        "\\n\\n,<|endoftext|>\n",
        "Task given: Please Write a Short story about a cat learning python Best Full Response:\n",
        "generative\n",
        "140\n",
        "0.85\n",
        "0.8\n",
        "<|endoftext|>\n",
        "Here is a short story (in the style of Tolkien) in which Aiden attacks a robot with a sword:\n",
        "generative\n",
        "140\n",
        "0.85\n",
        "0.8\n",
        "<|endoftext|>\n",
        "Use via API\n",
        "Â·\n",
        "Built with Gradiologo\n",
        "API documentation for\n",
        "https://hazzzardous-rwkv-instruct.hf.space/\n",
        "2 API endpoints:\n",
        "\n",
        "POST /run/predict\n",
        "Endpoint: https://hazzzardous-rwkv-instruct.hf.space/run/predict copy\n",
        "Input Payload\n",
        "{\n",
        "  \"data\": [\n",
        "\n",
        "hello world\n",
        " : string, // represents text string of 'Prompt' Textbox component\n",
        "\n",
        "Freeform\n",
        " : string, // represents selected choice of 'Choose Mode' Radio component\n",
        "\n",
        "40\n",
        " : number, // represents selected value of 'max_new_tokens' Slider component\n",
        "\n",
        "0.9\n",
        " : number, // represents selected value of 'temperature' Slider component\n",
        "\n",
        "0.85\n",
        " : number, // represents selected value of 'top_p' Slider component\n",
        "\n",
        "<|endoftext|>\n",
        " : string, // represents text string of 'stop' Textbox component\n",
        "\n",
        "0\n",
        " : number, // represents selected value of 'end_adj' Slider component\n",
        "  ]\n",
        "}\n",
        "Try It Out\n",
        "Response Object\n",
        "Code snippets\n",
        "import requests\n",
        "\n",
        "response = requests.post(\"https://hazzzardous-rwkv-instruct.hf.space/run/predict\", json={\n",
        "    \"data\": [\n",
        "        \"hello world\",\n",
        "        \"Freeform\",\n",
        "        40,\n",
        "        0.9,\n",
        "        0.85,\n",
        "        \"<|endoftext|>\",\n",
        "        0,\n",
        "    ]\n",
        "}).json()\n",
        "\n",
        "data = response[\"data\"]\n",
        "POST /run/predict_1\n",
        "Endpoint: https://hazzzardous-rwkv-instruct.hf.space/run/predict_1 copy\n",
        "Input Payload\n",
        "{\n",
        "  \"data\": [\n",
        "\n",
        "RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Ca\n",
        " lcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.   ------------------------------------------------------- [[\"USER: we meet again\\n\",\"FRIT SEGAARDR.\\n\"],[\"USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\n\",\"This one can you can be&lt;|endoftext|&gt;\"],[\"USER: hello world\\n\",\"FRIT:\\nFRIT: )\\nFRIT WILLI'm not what is your website urlopen a....\\nFRIT people\\nFRIT:\\n\\nFRIT:\\n\\nFRIT:\\nFRITP:-) i am FRIT:\\nFRIT: how are you must be like learning tool\\n\\n\\nFRIT:\\nFRIT:\\n\"],[\"USER: hello [[&quot;USER: we meet again\\\\n&quot;,&quot;FRIT SEGAARDR.\\\\n&quot;],[&quot;USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\\\n&quot;,&quot;This one can you can be&lt;|endoftext|&gt;&quot;],[&quot;USER: hello world\\\\n&quot;,&quot;FRIT:\\\\nFRIT: )\\\\nFRIT WILLI'm not what is your website urlopen a....\\\\nFRIT people\\\\nFRIT:\\\\n\\\\nFRIT:\\\\n\\\\nFRIT:\\\\nFRITP:-) i am FRIT:\\\\nFRIT: how are you must be like learning tool\\\\n\\\\n\\\\nFRIT:\\\\nFRIT:\\\\n&quot;]]\\n\",\"&lt;|endoftext|&gt;\"],[\"USER: Write an essay comparing Elon Musk to Thomas Midgley Jr.  Thomas Midgley nearly destroyed the ozone.  Elon musk nearly destroyed low earth orbit Essay:\\n\",\"FRIT people remember who was\\\\n\\\\nderog:  Thomas Midgis thomas midgrape of people's-POPINION/code-)\\\\n\\n\\nThe Greatness and who needs a long term paper,FRIT'\\nANSWOTRocketGreetech_Elon\\\\n\\n\\n\\nAmdashleyese, FRITRalph&lt;|endoftext|&gt;\"]]\n",
        " : string, // represents text string of 'Message' Textbox component\n",
        "\n",
        " : Any, // represents stored state value of 'history' State component\n",
        "\n",
        "60\n",
        " : number, // represents selected value of 'max_new_tokens' Slider componentp\n",
        "\n",
        "0.8\n",
        " : number, // represents selected value of 'temperature' Slider component\n",
        "\n",
        "0.85\n",
        " : number, // represents selected value of 'top_p' Slider component\n",
        "  ]\n",
        "}\n",
        "Try It Out\n",
        "Response Object\n",
        "Code snippets\n",
        "import requests\n",
        "\n",
        "response = requests.post(\"https://hazzzardous-rwkv-instruct.hf.space/run/predict_1\", json={\n",
        "    \"data\": [\n",
        "        \"RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.   ------------------------------------------------------- [[\"USER: we meet again\\n\",\"FRIT SEGAARDR.\\n\"],[\"USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\n\",\"This one can you can be&lt;|endoftext|&gt;\"],[\"USER: hello world\\n\",\"FRIT:\\nFRIT: )\\nFRIT WILLI'm not what is your website urlopen a....\\nFRIT people\\nFRIT:\\n\\nFRIT:\\n\\nFRIT:\\nFRITP:-) i am FRIT:\\nFRIT: how are you must be like learning tool\\n\\n\\nFRIT:\\nFRIT:\\n\"],[\"USER: hello [[&quot;USER: we meet again\\\\n&quot;,&quot;FRIT SEGAARDR.\\\\n&quot;],[&quot;USER: RF is just low frequency light. It behaves in a similar way to light being refracted and reflected.  The effects scale with wavelength, but you can get exactly the same effects in mirrors, blocks of transparent (to light or RF) material, lenses and waveguides (or light fibers) with RF and light or infra-red.  The scale difference is huge.  Light is around 0.5 of a micrometer wavelength, microwaves are a few centimeters, AM radio is perhaps 300 meters wavelength.  They can all be treated as waves or as photons, and quantum mechanics applies just the same to them all. When you put a pencil in a fishtank, it seems to bend. That same refraction happens with radio waves, they travel more slowly in dielectrics than in a vacuum because of the quantum effects, but that doesn't matter for large objects like these. A slanting dielectric surface can bend the rays of light or radio energy.  If the slanted surface is in the shape of a curved magnifying glass, the amount of bending varies across the glass, with more bending at the edges, so a parallel beam of light like from the Sun gets focussed to a point.  Exactly the same happens with radio waves so long as the glass is more than ten wavelengths across and the source is emitting radio waves.  You might want to use PTFE or a similar RF-transparent plastic to make the lens as it's much clearer than glass at millimeter wavelengths. At Infra red around 10 micrometers wavelength, Germanium metal lenses work well as they are transparent to IR, as is Calcium Fluoride.   OK, so we are halfway.  Now instead of making the lens shaped like a magnifying glass, we can change the density of the material by putting larger holes (or more holes) in it to reduce its average density, varying that density across the body of the material.  If you pick the rate of change of density just right, the effect on mmWave energy is indistinguishable from that of the original magnifying glass shape, but it's way easier to make and mount.  You can also do really complex tapers of density that would be impossible to machine.  That's the benefit of this technology, it takes us way beyond what can be done with casting, injection molding, electroforming, laser cutting, water jets, Wire EDM or CNC machining, at least for ceramic-filled photopolymers.\\\\n&quot;,&quot;This one can you can be&lt;|endoftext|&gt;&quot;],[&quot;USER: hello world\\\\n&quot;,&quot;FRIT:\\\\nFRIT: )\\\\nFRIT WILLI'm not what is your website urlopen a....\\\\nFRIT people\\\\nFRIT:\\\\n\\\\nFRIT:\\\\n\\\\nFRIT:\\\\nFRITP:-) i am FRIT:\\\\nFRIT: how are you must be like learning tool\\\\n\\\\n\\\\nFRIT:\\\\nFRIT:\\\\n&quot;]]\\n\",\"&lt;|endoftext|&gt;\"],[\"USER: Write an essay comparing Elon Musk to Thomas Midgley Jr.  Thomas Midgley nearly destroyed the ozone.  Elon musk nearly destroyed low earth orbit Essay:\\n\",\"FRIT people remember who was\\\\n\\\\nderog:  Thomas Midgis thomas midgrape of people's-POPINION/code-)\\\\n\\n\\nThe Greatness and who needs a long term paper,FRIT'\\nANSWOTRocketGreetech_Elon\\\\n\\n\\n\\nAmdashleyese, FRITRalph&lt;|endoftext|&gt;\"]]\",\n",
        "        None,\n",
        "        60,\n",
        "        0.8,\n",
        "        0.85,\n",
        "    ]\n",
        "}).json()\n",
        "\n",
        "data = response[\"data\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kPXbzWZMG0x"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI7DmRInE9_7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(\"https://hazzzardous-rwkv-instruct.hf.space/run/predict\", json={\n",
        "\t\"data\": [\n",
        "\t\t\"how have youGmail by Google\n",
        "Search\n",
        "Refresh\n",
        "2 of hundreds\n",
        "Previous conversation\n",
        "Next conversation\n",
        "New Newsletter, who dis? â¨ð\n",
        "Google Assistant - 5:17â¯pm\n",
        "to Krognus\n",
        "The Google Assistant Chatter Newsletter masthead.\n",
        "\n",
        "Beep boop beep, John! ð/ð\n",
        "\n",
        "That's the sound of us ramping up Google Assistant's new monthly email. While you can expect the usual tips to help you make the most of your Assistant, we'll also pepper in the latest news to keep you in the loop. Speaking of what's recent, did you catch our commercial<https://notifications.google.com/g/p/APdRdFwnH4ChQJhrrOAdehOEZs7iXHxkFJkNQQFSD2PupQlpUYm0mLAFWM-UiYaxzZp6vBPTkWGbZupbrFy-294nBOe9zVp2pN4BCyOFV7fGpHX23NyYHWRh3wWJQsFE1ZvN7LDpNYMe-jmNDYGgEgA69aiUlbRe_dOcONK2P7ppS8R8sNrz8upggJXSt7vZu4vflQoHlL7Hi0zRXrhsdU1SmVR9PWA_jcnisZAs_sILPA> that aired during the big game? ð\n",
        "\n",
        " Black history\n",
        "\n",
        "Let's go explore!\n",
        "\n",
        "Feature Spotlight\n",
        "ð¦ï¸ Easily check the weather\n",
        "\n",
        "A woman decides what to wear as a speech bubble containing a weather icon comes out of her nearby phone.\n",
        "\n",
        "Your Assistant is the MVP of weather forecasts. ð\n",
        "\n",
        "Ask anytime with just a few words to get a play-by-play of highs, lows, and what to expect in between.\n",
        "\n",
        "You can hear about what the weather will be like in a certain city on a specific day with details like UV index, wind conditions, and more included. ð\n",
        "\n",
        "Be prepared. Just ask \"Hey Googleâ¦\"\n",
        "\n",
        "ð \"What's the weather today?\"\n",
        "\n",
        "âï¸ \"Do I need an umbrella?\"\n",
        "\n",
        "ð \"What will the temperature be this weekend in Boston?\"\n",
        "\n",
        "âï¸ \"What's the air quality?\"\n",
        "\n",
        "\n",
        "You Might Like\n",
        "Here's what else we're chatting about this month:\n",
        "\n",
        "â A quick way to check the weather forecast\n",
        "\n",
        "ðï¸ What's new in the world of tech\n",
        "\n",
        "ð¤ Highlights of important leaders throughout\n",
        "ð Stream your heart out\n",
        "\n",
        "With Assistant, you can play your top tracks on your favorite streaming serviceâall you have to do is link your provider in your Google Assistant settings.\n",
        "\n",
        "Ready to jam out? ð¤\n",
        "\n",
        "Link my\n",
        "(0/3 pages) Next >\n",
        "Reply\n",
        "Reply all\n",
        "Forward\n",
        "Archive\n",
        "Delete\n",
        "Report spam\n",
        "Add star\n",
        "Mark as unread\n",
        "krognus@gmail.com | Sign out\n",
        "Help | Terms of Service\n",
        "Â©2023 Google been\",\n",
        "\t\t\"Expert\",\n",
        "\t\t140,\n",
        "\t\t0.9,\n",
        "\t\t0.85,\n",
        "\t\t\"null\",\n",
        "\t\t0,\n",
        "\t]\n",
        "}).json()\n",
        "\n",
        "data = response[\"data\"]\n",
        "\n",
        "print (data)\n",
        "\n",
        "print (data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3tFe35LF5rB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWa9Lhx2II2n",
        "outputId": "a36746a0-7362-473a-ac71-81823a5046d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting inquirer\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting blessed>=1.19.0 (from inquirer)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer) (67.7.2)\n",
            "Installing collected packages: python-editor, readchar, blessed, inquirer\n",
            "Successfully installed blessed-1.20.0 inquirer-3.1.3 python-editor-1.0.4 readchar-4.0.5\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.38.0-py3-none-any.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.10 (from gradio)\n",
            "  Downloading gradio_client-0.2.10-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.0.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.11)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.10->gradio) (2023.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.4)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=7ea6dce112d1d6a483b81ac5b33f547a773a3b067ce89172d2cf8e36985f35c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, markdown-it-py, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, linkify-it-py, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.100.0 ffmpy-0.3.1 gradio-3.38.0 gradio-client-0.2.10 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 orjson-3.9.2 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.23.1 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install inquirer\n",
        "!pip install rwkvstic>=0.3.3\n",
        "!pip install scipy\n",
        "!pip install onnx\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAbfCqzlN6eA",
        "outputId": "28131068-0897-4ddb-b457-32d4d7a88f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: config in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement title (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for title\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install config\n",
        "!pip install title\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "xwqiFbZPKz_Z",
        "outputId": "4ebc6d22-7cec-4ae0-d0e0-cb19c05c2491"
      },
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7ff34376a011>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \t]\n\u001b[0;32m---> 11\u001b[0;31m }).json()\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: [Errno Expecting value] Your space is on error, check its status on hf.co: 0"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(\"https://hazzzardous-rwkv-instruct.hf.space/run/predict_1\", json={\n",
        "\t\"data\": [\n",
        "\t\t\"hekki\",\n",
        "\t\tNone,\n",
        "\t\t60,\n",
        "\t\t0.8,\n",
        "\t\t0.85,\n",
        "\t]\n",
        "}).json()\n",
        "\n",
        "data = response[\"data\"]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "f6VGFrsLHuTv",
        "outputId": "e90b0309-9d9b-4047-e5b4-7c264d6c5608"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-79bd99646acb>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrwkvstic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRWKV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrwkvstic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\"\"\" from config import config, title\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'config' from 'rwkvstic.load' (/usr/local/lib/python3.10/dist-packages/rwkvstic/load.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "RWKV RNN Model - Gradio Space for HuggingFace\n",
        "YT - Mean Gene Hacks - https://www.youtube.com/@MeanGeneHacks\n",
        "(C) Gene Ruebsamen - 2/7/2023\n",
        "This program is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU General Public License as published by\n",
        "the Free Software Foundation, either version 3 of the License, or\n",
        "(at your option) any later version.\n",
        "This program is distributed in the hope that it will be useful,\n",
        "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "GNU General Public License for more details.\n",
        "You should have received a copy of the GNU General Public License\n",
        "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
        "AgnosticRWKV\n",
        "\"\"\"\n",
        "\n",
        "import gradio as gr\n",
        "import codecs\n",
        "from ast import literal_eval\n",
        "from datetime import datetime\n",
        "from rwkvstic.load import RWKV\n",
        "from rwkvstic.load import config, title as config, title\n",
        "\"\"\" from config import config, title\"\"\"\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "desc = '''<p>RNN with Transformer-level LLM Performance (<a href='https://github.com/BlinkDL/RWKV-LM'>github</a>).\n",
        "    According to the author: \"It combines the best of RNN and transformers - great performance, fast inference, saves VRAM, fast training, \"infinite\" ctx_len, and free sentence embedding.\"'''\n",
        "\n",
        "thanks = '''<p>Thanks to <a href='https://github.com/gururise/rwkv_gradio'>Gururise</a> for this template</p>'''\n",
        "\n",
        "\n",
        "def to_md(text):\n",
        "    return text.replace(\"\\n\", \"<br />\")\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = None\n",
        "    model = RWKV(\n",
        "        **config\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "\n",
        "\n",
        "def infer(\n",
        "        prompt,\n",
        "        mode=\"generative\",\n",
        "        max_new_tokens=10,\n",
        "        temperature=0.1,\n",
        "        top_p=1.0,\n",
        "        stop=\"<|endoftext|>\",\n",
        "        end_adj=0.0,\n",
        "        seed=42,\n",
        "):\n",
        "    global model\n",
        "\n",
        "    if model == None:\n",
        "        gc.collect()\n",
        "        if (DEVICE == \"cuda\"):\n",
        "            torch.cuda.empty_cache()\n",
        "        model = get_model()\n",
        "\n",
        "    max_new_tokens = int(max_new_tokens)\n",
        "    temperature = float(temperature)\n",
        "    end_adj = float(end_adj)\n",
        "    top_p = float(top_p)\n",
        "    stop = [x.strip(' ') for x in stop.split(',')]\n",
        "    seed = seed\n",
        "\n",
        "    assert 1 <= max_new_tokens <= 512\n",
        "    assert 0.0 <= temperature <= 5.0\n",
        "    assert 0.0 <= top_p <= 1.0\n",
        "\n",
        "    temperature = max(0.05, temperature)\n",
        "    if prompt == \"\":\n",
        "        prompt = \" \"\n",
        "\n",
        "    # Clear model state for generative mode\n",
        "    model.resetState()\n",
        "    if (mode == \"Q/A\"):\n",
        "        prompt = f\"\\nQ: {prompt}\\n\\nA:\"\n",
        "    if (mode == \"ELDR\"):\n",
        "        prompt = f\"\\n{prompt}\\n\\nExpert Long Detailed Response:\\n\\nHi, thanks for reaching out, we would be happy to answer your question\"\n",
        "    if (mode == \"Expert\"):\n",
        "        prompt = f\"\\n{prompt}\\n\\nExpert Full Response:\\n\\nHi, thanks for reaching out, we would be happy to answer your question.\\n\"\n",
        "    if (mode == \"EFA\"):\n",
        "        prompt = f'\\nAsk Expert\\n\\nQuestion:\\n{prompt}\\n\\nExpert Full Answer:\\n'\n",
        "    if (mode == \"BFR\"):\n",
        "        prompt = f\"Task given:\\n\\n{prompt}\\n\\nBest Full Response:\"\n",
        "\n",
        "    print(f\"PROMPT ({datetime.now()}):\\n-------\\n{prompt}\")\n",
        "    print(f\"OUTPUT ({datetime.now()}):\\n-------\\n\")\n",
        "    # Load prompt\n",
        "    model.loadContext(newctx=prompt)\n",
        "    generated_text = \"\"\n",
        "    done = False\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new_tokens):\n",
        "            char = model.forward(stopStrings=stop, temp=temperature, top_p_usual=top_p, end_adj=end_adj)[\n",
        "                \"output\"]\n",
        "            print(char, end='', flush=True)\n",
        "            generated_text += char\n",
        "            generated_text = generated_text.lstrip(\"\\n \")\n",
        "\n",
        "            for stop_word in stop:\n",
        "                stop_word = codecs.getdecoder(\"unicode_escape\")(stop_word)[0]\n",
        "                if stop_word != '' and stop_word in generated_text:\n",
        "                    done = True\n",
        "                    break\n",
        "            yield generated_text\n",
        "            if done:\n",
        "                print(\"<stopped>\\n\")\n",
        "                break\n",
        "\n",
        "    # print(f\"{generated_text}\")\n",
        "\n",
        "    for stop_word in stop:\n",
        "        stop_word = codecs.getdecoder(\"unicode_escape\")(stop_word)[0]\n",
        "        if stop_word != '' and stop_word in generated_text:\n",
        "            generated_text = generated_text[:generated_text.find(stop_word)]\n",
        "\n",
        "    gc.collect()\n",
        "    yield generated_text\n",
        "username = \"USER\"\n",
        "intro = f'''The following is a verbose and detailed conversation between an AI assistant called FRITZ, and a human user called USER. FRITZ is intelligent, knowledgeable, wise and polite.\n",
        "    {username}: What year was the french revolution?\n",
        "    FRITZ: The French Revolution started in 1789, and lasted 10 years until 1799.\n",
        "    {username}: 3+5=?\n",
        "    FRITZ: The answer is 8.\n",
        "    {username}: What year did the Berlin Wall fall?\n",
        "    FRITZ: The Berlin wall stood for 28 years and fell in 1989.\n",
        "    {username}: solve for a: 9-a=2\n",
        "    FFRITZRITZ: The answer is a=7, because 9-7 = 2.\n",
        "    {username}: wat is lhc\n",
        "    FRITZ: The Large Hadron Collider (LHC) is a high-energy particle collider, built by CERN, and completed in 2008. It was used to confirm the existence of the Higgs boson in 2012.\n",
        "    {username}: Tell me about yourself.\n",
        "    FRITZ: My name is Fritz. I am an RNN based Large Language Model (LLM).\n",
        "    '''\n",
        "\n",
        "model.loadContext(newctx=intro)\n",
        "chatState = model.getState()\n",
        "model.resetState()\n",
        "def chat(\n",
        "        prompt,\n",
        "        history,\n",
        "        max_new_tokens=10,\n",
        "        temperature=0.1,\n",
        "        top_p=1.0,\n",
        "        seed=42,\n",
        "):\n",
        "    global model\n",
        "    global username\n",
        "    history = history or []\n",
        "\n",
        "    intro = \"\"\n",
        "\n",
        "    if model == None:\n",
        "        gc.collect()\n",
        "        if (DEVICE == \"cuda\"):\n",
        "            torch.cuda.empty_cache()\n",
        "        model = get_model()\n",
        "\n",
        "    username = username.strip()\n",
        "    username = username or \"USER\"\n",
        "\n",
        "\n",
        "\n",
        "    if len(history) == 0:\n",
        "        # no history, so lets reset chat state\n",
        "        model.setState(chatState)\n",
        "        history = [[], model.emptyState]\n",
        "        print(\"reset chat state\")\n",
        "    else:\n",
        "        if (history[0][0][0].split(':')[0] != username):\n",
        "            model.setState(chatState)\n",
        "            history = [[], model.chatState]\n",
        "            print(\"username changed, reset state\")\n",
        "        else:\n",
        "            model.setState(history[1])\n",
        "            intro = \"\"\n",
        "\n",
        "    max_new_tokens = int(max_new_tokens)\n",
        "    temperature = float(temperature)\n",
        "    top_p = float(top_p)\n",
        "    seed = seed\n",
        "\n",
        "    assert 1 <= max_new_tokens <= 512\n",
        "    assert 0.0 <= temperature <= 3.0\n",
        "    assert 0.0 <= top_p <= 1.0\n",
        "\n",
        "    temperature = max(0.05, temperature)\n",
        "\n",
        "    prompt = f\"{username}: \" + prompt + \"\\n\"\n",
        "    print(f\"CHAT ({datetime.now()}):\\n-------\\n{prompt}\")\n",
        "    print(f\"OUTPUT ({datetime.now()}):\\n-------\\n\")\n",
        "    # Load prompt\n",
        "\n",
        "    model.loadContext(newctx=prompt)\n",
        "\n",
        "    out = model.forward(number=max_new_tokens, stopStrings=[\n",
        "                        \"<|endoftext|>\", username+\":\"], temp=temperature, top_p_usual=top_p)\n",
        "\n",
        "    generated_text = out[\"output\"].lstrip(\"\\n \")\n",
        "    generated_text = generated_text.rstrip(username+\":\")\n",
        "    print(f\"{generated_text}\")\n",
        "\n",
        "    gc.collect()\n",
        "    history[0].append((prompt, generated_text))\n",
        "    return history[0], [history[0], out[\"state\"]]\n",
        "\n",
        "\n",
        "examples = [\n",
        "    [\n",
        "        # Question Answering\n",
        "        '''What is the capital of Germany?''', \"Q/A\", 25, 0.2, 1.0, \"<|endoftext|>\"],\n",
        "    [\n",
        "        # Question Answering\n",
        "        '''Are humans good or bad?''', \"Q/A\", 150, 0.8, 0.8, \"<|endoftext|>\"],\n",
        "    [\n",
        "        # Question Answering\n",
        "        '''What is the purpose of Vitamin A?''', \"Q/A\", 50, 0.2, 0.8, \"<|endoftext|>\"],\n",
        "    [\n",
        "        # Chatbot\n",
        "        '''This is a conversation between two AI large language models named Alex and Fritz. They are exploring each other's capabilities, and trying to ask interesting questions of one another to explore the limits of each others AI.\n",
        "Conversation:\n",
        "Alex: Good morning, Fritz, what type of LLM are you based upon?\n",
        "Fritz: Morning Alex, I am an RNN with transformer level performance. My language model is 100% attention free.\n",
        "Alex:''', \"generative\", 220, 0.9, 0.9, \"\\\\n\\\\n,<|endoftext|>\"],\n",
        "    [\n",
        "        # Generate List\n",
        "        '''Task given:\n",
        "Please Write a Short story about a cat learning python\n",
        "Best Full Response:\n",
        "''', \"generative\", 140, 0.85, 0.8, \"<|endoftext|>\"],\n",
        "    [\n",
        "        # Natural Language Interface\n",
        "        '''Here is a short story (in the style of Tolkien) in which Aiden attacks a robot with a sword:\n",
        "        ''', \"generative\", 140, 0.85, 0.8, \"<|endoftext|>\"]\n",
        "]\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=infer,\n",
        "    description=f'''<h3>Generative and Question/Answer</h3>{desc}{thanks}''',\n",
        "    allow_flagging=\"never\",\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=20, label=\"Prompt\"),  # prompt\n",
        "        gr.Radio([\"Freeform\", \"Q/A\",\"ELDR\",\"Expert\",\"EFR\",\"BFR\"],\n",
        "                 value=\"Expert\", label=\"Choose Mode\"),\n",
        "        gr.Slider(1, 512, value=40),  # max_tokens\n",
        "        gr.Slider(0.0, 5.0, value=0.9),  # temperature\n",
        "        gr.Slider(0.0, 1.0, value=0.85),  # top_p\n",
        "        gr.Textbox(lines=1, value=\"<|endoftext|>\"),  # stop\n",
        "        gr.Slider(-999, 0.0, value=0.0),  # end_adj\n",
        "\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Output\", lines=25),\n",
        "    examples=examples,\n",
        "    cache_examples=False,\n",
        ").queue()\n",
        "\n",
        "chatiface = gr.Interface(\n",
        "    fn=chat,\n",
        "    description=f'''<h3>Chatbot</h3><h4>Refresh page or change name to reset memory context</h4>{desc}{thanks}''',\n",
        "    allow_flagging=\"never\",\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, label=\"Message\"),  # prompt\n",
        "        \"state\",\n",
        "        gr.Slider(1, 256, value=60),  # max_tokens\n",
        "        gr.Slider(0.0, 1.0, value=0.8),  # temperature\n",
        "        gr.Slider(0.0, 1.0, value=0.85)  # top_p\n",
        "    ],\n",
        "    outputs=[gr.Chatbot(label=\"Chat Log\", color_map=(\n",
        "        \"green\", \"pink\")), \"state\"],\n",
        ").queue()\n",
        "\n",
        "demo = gr.TabbedInterface(\n",
        "\n",
        "    [iface, chatiface], [\"Q/A\", \"Chatbot\"],\n",
        "    title=title,\n",
        "\n",
        ")\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FbjdzRklLrF"
      },
      "outputs": [],
      "source": [
        "from rwkvstic.agnostic.backends import TORCH, TORCH_QUANT\n",
        "import torch\n",
        "\n",
        "quantized = {\n",
        "    \"mode\": TORCH_QUANT,\n",
        "    \"runtimedtype\": torch.bfloat16,\n",
        "    \"useGPU\": torch.cuda.is_available(),\n",
        "    \"chunksize\": 32,  # larger = more accurate, but more memory\n",
        "    \"target\": 100  # your gpu max size, excess vram offloaded to cpu\n",
        "}\n",
        "\n",
        "# UNCOMMENT TO SELECT OPTIONS\n",
        "# Not full list of options, see https://pypi.org/project/rwkvstic/ and https://huggingface.co/BlinkDL/ for more models/modes\n",
        "\n",
        "# RWKV 1B5 instruct test 1 model\n",
        "# Approximate\n",
        "# [Vram usage: 6.0GB]\n",
        "# [File size: 3.0GB]\n",
        "\n",
        "\n",
        "config = {\n",
        "    \"path\":\"https://huggingface.co/BlinkDL/rwkv-4-pile-7b/resolve/main/RWKV-4-Pile-7B-Instruct-test2-20230209.pth\",\n",
        "    \"mode\":TORCH,\n",
        "    \"runtimedtype\":torch.float64,\n",
        "    \"useGPU\":torch.cuda.is_available(),\n",
        "    \"dtype\":torch.bfloat16,\n",
        "    #\"useLogFix\":False # When enabled, use BlinkDLs version of the att.\n",
        "}\n",
        "\n",
        "title = \"RWKV-4 (7B Instruct v2)\"\n",
        "\n",
        "# RWKV 1B5 instruct model quantized\n",
        "# Approximate\n",
        "# [Vram usage: 1.3GB]\n",
        "# [File size: 3.0GB]\n",
        "\n",
        "# config = {\n",
        "#     \"path\": \"https://huggingface.co/BlinkDL/rwkv-4-pile-1b5/resolve/main/RWKV-4-Pile-1B5-Instruct-test1-20230124.pth\",\n",
        "#     **quantized\n",
        "# }\n",
        "\n",
        "# title = \"RWKV-4 (1.5b Instruct Quantized)\"\n",
        "\n",
        "# RWKV 7B instruct pre-quantized (settings baked into model)\n",
        "# Approximate\n",
        "# [Vram usage: 7.0GB]\n",
        "# [File size: 8.0GB]\n",
        "\n",
        "# config = {\n",
        "#     \"path\": \"https://huggingface.co/Hazzzardous/RWKV-8Bit/resolve/main/RWKV-4-Pile-7B-Instruct.pqth\"\n",
        "# }\n",
        "\n",
        "# title = \"RWKV-4 (7b Instruct Quantized)\"\n",
        "\n",
        "# RWKV 14B quantized (latest as of feb 9)\n",
        "# Approximate\n",
        "# [Vram usage: 15.0GB]\n",
        "# [File size: 15.0GB]\n",
        "\n",
        "# config = {\n",
        "#     \"path\": \"https://huggingface.co/Hazzzardous/RWKV-8Bit/resolve/main/RWKV-4-Pile-14B-20230204-7324.pqth\"\n",
        "# }\n",
        "\n",
        "# title = \"RWKV-4 (14b 94% trained, not yet instruct tuned, 8-Bit)\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe1gsrhiqm4agIynQ3D+gf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}